{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Sequence To Sequence Model with Multi-Head Attention</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tb 2019-01-20 \n",
      "\n",
      "CPython 3.6.4\n",
      "IPython 6.2.1\n",
      "\n",
      "sys 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 12:04:33) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy 1.14.2\n",
      "pandas 0.22.0\n",
      "sklearn 0.19.2\n",
      "torch 1.0.0a0+1e45e7a\n",
      "IPython 6.2.1\n",
      "\n",
      "compiler   : GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)\n",
      "system     : Darwin\n",
      "release    : 17.5.0\n",
      "machine    : x86_64\n",
      "processor  : i386\n",
      "CPU cores  : 24\n",
      "interpreter: 64bit\n",
      "GPU Name: TITAN Xp\n",
      "GPU Memory: 12.0GB\n",
      "CUDA Version: (9, 1, 0)\n",
      "GPU Free/Total Memory: 89%\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchtext\n",
    "from torchtext.data import Field\n",
    "\n",
    "from lib.checkpoint import *\n",
    "from lib.stopping import Stopping\n",
    "from lib.tools import *\n",
    "from lib.trainlogger import *\n",
    "from lib.utilities import *\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -a \"tb\" -d -v -m -p sys,numpy,pandas,sklearn,torch,IPython\n",
    "gpu_stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.is_available = lambda : False\n",
    "# torch.backends.cudnn.enabled=False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = HYPERPARAMETERS({\n",
    "    'EXPERIMENT': 'Eng2Ger',\n",
    "    'DESCRIPTION': 'Sequence To Sequence model',\n",
    "    'TIMESTAMP': HYPERPARAMETERS.create_timestamp(),\n",
    "\n",
    "    'MODEL_NAME': 'Eng2Ger_ENC_DEC',\n",
    "\n",
    "    'PRELOAD_MODEL_PATH': None, #'Eng2Ger_ENC_DEC.tar',\n",
    "\n",
    "    'ROOT_DIR': 'data',\n",
    "\n",
    "    'TARGET_ENCODING': 'sts',  # ' ctc\n",
    "\n",
    "    'BATCH_SIZE': 128,\n",
    "    'NUM_WORKERS': 8,\n",
    "\n",
    "    'EMBEDDING_SIZE': 256,\n",
    "    'EMBEDDING_DROPOUT': 0.2,\n",
    "    'RNN_HIDDEN_SIZE': 256,\n",
    "    'RNN_NUM_LAYERS': 2,\n",
    "    'RNN_DROPOUT': 0.2,\n",
    "    'BIDIRECTIONAL': True,\n",
    "\n",
    "    'LR': 0.001,\n",
    "    'LR_LAMBDA': lambda epoch: max(math.pow(0.78, math.floor((1 + epoch) / 200.0)), 0.01),\n",
    "    'WEIGHT_DECAY': 0,\n",
    "    'MOMENTUM': 0.9,\n",
    "    'NESTEROV': True,\n",
    "\n",
    "    'TEACHER_FORCING_RATIO': 0.5,\n",
    "\n",
    "    'LABEL_SMOOTHING' : 0.2,\n",
    "\n",
    "    'MAX_GRAD_NORM': 400,\n",
    "\n",
    "    'MAX_EPOCHS': 30,\n",
    "\n",
    "    'STOPPING_PATIENCE': 80,\n",
    "\n",
    "    'CHECKPOINT_INTERVAL': 10,\n",
    "    'CHECKPOINT_RESTORE': False,\n",
    "\n",
    "    'USE_CUDA': torch.cuda.is_available(),\n",
    "\n",
    "    'SEED': 123456,\n",
    "    \n",
    "    'SEQ_MAX_LEN' :         50,\n",
    "    'SRC_VOCAB_MAX_SIZE' :  50000,\n",
    "    'TGT_VOCAB_MAX_SIZE' :  50000,\n",
    "\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(H.SEED)\n",
    "np.random.seed(H.SEED)\n",
    "torch.manual_seed(H.SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(H.SEED)\n",
    "    torch.cuda.manual_seed_all(H.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYM_SOS = '<sos>'\n",
    "SYM_EOS = '<eos>'\n",
    "SYM_PAD = '<pad>'\n",
    "IDX_SOS = -1\n",
    "IDX_EOS = -1\n",
    "IDX_PAD = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "spacy_en = spacy.load('en')\n",
    "spacy_de = spacy.load('de')\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer( text )]\n",
    "    return text.split()\n",
    "\n",
    "def tokenize_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "    return text.split()\n",
    "\n",
    "preproc = lambda seq: seq + [SYM_EOS]\n",
    "\n",
    "src = Field(sequential=True, tokenize=tokenize_en, lower=True, batch_first=True, \n",
    "            include_lengths=True)\n",
    "tgt = Field(sequential=True, tokenize=tokenize_de, lower=True, batch_first=True, init_token= SYM_SOS,\n",
    "            include_lengths=True, preprocessing=preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_filter(example):\n",
    "    return len(example.src) <= H.SEQ_MAX_LEN and len(example.tgt) <= H.SEQ_MAX_LEN\n",
    "\n",
    "path = os.path.join(H.ROOT_DIR, \"eng-ger-data.tsv\")\n",
    "SRC_FIELD_NAME = 'src'\n",
    "TGT_FIELD_NAME = 'tgt'\n",
    "\n",
    "\n",
    "train_data, valid_data, test_data= torchtext.data.TabularDataset(\n",
    "    path=path, format='tsv',\n",
    "    fields=[(SRC_FIELD_NAME, src), (TGT_FIELD_NAME, tgt)],\n",
    "    filter_pred=len_filter\n",
    "    ).split(split_ratio=[0.8, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    def __init__(self, vocab):\n",
    "        self.vocab = vocab\n",
    "        \n",
    "    def __call__(self, val):\n",
    "        if isinstance(val, str):\n",
    "            res = self.vocab.stoi[val] if val in self.vocab.stoi else None\n",
    "        elif isinstance(val, int):\n",
    "            res = self.vocab.itos[val] if val <= self.__len__() else None\n",
    "        else:\n",
    "            raise RuntimeError\n",
    "        return res   \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.vocab.itos)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'Vocab(size=' + str(len(self.vocab.itos)) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab(size=9510) Vocab(size=15657)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 2, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.build_vocab(train_data, max_size=H.SRC_VOCAB_MAX_SIZE, min_freq=2)\n",
    "tgt.build_vocab(train_data, max_size=H.TGT_VOCAB_MAX_SIZE, min_freq=2)\n",
    "\n",
    "input_vocab = Vocabulary(src.vocab)\n",
    "output_vocab = Vocabulary(tgt.vocab)\n",
    "\n",
    "print(input_vocab, output_vocab)\n",
    "\n",
    "IDX_PAD = output_vocab(SYM_PAD)\n",
    "IDX_SOS = output_vocab(SYM_SOS)\n",
    "IDX_EOS = output_vocab(SYM_EOS)\n",
    "\n",
    "IDX_PAD, IDX_SOS, IDX_EOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<eos>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_vocab(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1058, 133, 133)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iter, valid_iter, test_iter = torchtext.data.BucketIterator.splits(\n",
    "                                (train_data, valid_data, test_data), \n",
    "                                batch_size=H.BATCH_SIZE, repeat=False, \n",
    "                                sort=False, sort_within_batch=True, \n",
    "                                sort_key=lambda x: len(x.src))\n",
    "\n",
    "\n",
    "batch = next(train_iter.__iter__())\n",
    "input_variables = getattr(batch, 'src')\n",
    "target_variables = getattr(batch, 'tgt')\n",
    "\n",
    "len(train_iter), len(valid_iter), len(test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx_batch, batch in enumerate(train_iter):\n",
    "    inputs_cpu, input_sizes_cpu = getattr(batch, SRC_FIELD_NAME)\n",
    "    labels_cpu, label_sizes_cpu = getattr(batch, TGT_FIELD_NAME)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, bidirectional=False, dropout=0.5):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.dropout = dropout if num_layers > 1 else 0.0\n",
    "\n",
    "        self.rnn = nn.GRU(self.input_size, self.hidden_size, self.num_layers, batch_first=True, bias=True,\n",
    "                          dropout=self.dropout, bidirectional=self.bidirectional)\n",
    "\n",
    "    def forward(self, inputs, lengths):\n",
    "        pack_seq = nn.utils.rnn.pack_padded_sequence(inputs, lengths, batch_first=True)\n",
    "        pack_seq, hidden = self.rnn(pack_seq)\n",
    "        outputs, lengths = nn.utils.rnn.pad_packed_sequence(pack_seq, batch_first=True)\n",
    "        return outputs, lengths, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size=128, num_layers=1, \n",
    "                 embedding_dropout=0, rnn_dropout=0, bidirectional=True, initialize=None):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.embedding_dropout = embedding_dropout\n",
    "        self.rnn_dropout = rnn_dropout\n",
    "        self.initialize = initialize\n",
    "\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Embedding(self.vocab_size, self.embedding_size),\n",
    "            nn.Dropout(self.embedding_dropout) \n",
    "        )        \n",
    "        \n",
    "        self.rnn = RNN(self.embedding_size, self.hidden_size, self.num_layers, \n",
    "                       dropout=self.rnn_dropout, bidirectional=self.bidirectional)\n",
    "\n",
    "        if self.initialize is not None:\n",
    "            self.initialize(self)\n",
    "\n",
    "    def forward(self, inputs, input_sizes):\n",
    "\n",
    "        outputs = self.embedding(inputs)\n",
    "\n",
    "        outputs, output_lengths, hidden = self.rnn(outputs, input_sizes)\n",
    "        \n",
    "        hidden = self._cat(hidden)\n",
    "\n",
    "        return outputs, output_lengths, hidden\n",
    "\n",
    "    def _cat(self, h):\n",
    "        \"\"\"\n",
    "        (#directions * #layers, #batch, hidden_size) -> (#layers, #batch, #directions * hidden_size)\n",
    "        \"\"\"\n",
    "        if self.bidirectional:\n",
    "            h = torch.cat([h[0:h.size(0):2], h[1:h.size(0):2]], 2)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for model: Encoder\n",
      "________________________________________________________________________________\n",
      "Layer (type)                        Shape                           Param #     \n",
      "================================================================================\n",
      "embedding.0 (Embedding)             ((9510, 256),)                  2434560     \n",
      "________________________________________________________________________________\n",
      "embedding.1 (Dropout)               ()                              0           \n",
      "________________________________________________________________________________\n",
      "rnn.rnn (GRU)                       ((768, 256), (768, 256), (768,) 1972224     \n",
      "================================================================================\n",
      "Total params:         4,406,784\n",
      "Trainable params:     4,406,784\n",
      "________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 7, 512]), torch.Size([128]), torch.Size([2, 128, 512]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_cpu = Encoder(len(input_vocab), H.EMBEDDING_SIZE, H.RNN_HIDDEN_SIZE, \n",
    "                         num_layers=H.RNN_NUM_LAYERS, rnn_dropout=H.RNN_DROPOUT, \n",
    "                         embedding_dropout=H.EMBEDDING_DROPOUT)\n",
    "\n",
    "enc_outputs_cpu, enc_output_sizes_cpu, enc_hidden_cpu = encoder_cpu(inputs_cpu, input_sizes_cpu)\n",
    "\n",
    "print(model_summary(encoder_cpu))\n",
    "\n",
    "enc_outputs_cpu.shape, enc_output_sizes_cpu.shape, enc_hidden_cpu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, p):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.h = h\n",
    "        self.d = d_model\n",
    "        self.d_head = d_model // h\n",
    "        self.fc_query = nn.Linear(d_model, h * self.d_head, bias=False)\n",
    "        self.fc_key = nn.Linear(d_model, h * self.d_head, bias=False)\n",
    "        self.fc_value = nn.Linear(d_model, h * self.d_head, bias=False)\n",
    "        self.fc_concat = nn.Linear(h * self.d_head, d_model, bias=False)\n",
    "        self.sm = nn.Softmax(dim=1)\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.attn_dropout = nn.Dropout(p)\n",
    "        self.layernorm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def _prepare_proj(self, x):\n",
    "        \"\"\"Reshape the projectons to apply softmax on each head\n",
    "\n",
    "        \"\"\"\n",
    "        b, l, d = x.size()\n",
    "        return x.view(b, l, self.h, self.d_head).transpose(1, 2).contiguous().view(b * self.h, l, self.d_head)\n",
    "\n",
    "    def forward(self, query, key, value, mask):\n",
    "        b, len_query = query.size(0), query.size(1)\n",
    "        len_key = key.size(1)\n",
    "\n",
    "        # project inputs to multi-heads\n",
    "        proj_query = self.fc_query(query)  # batch_size x len_query x h*d_head\n",
    "        proj_key = self.fc_key(key)  # batch_size x len_key x h*d_head\n",
    "        proj_value = self.fc_value(value)  # batch_size x len_key x h*d_head\n",
    "\n",
    "        # prepare the shape for applying softmax\n",
    "        proj_query = self._prepare_proj(proj_query)  # batch_size*h x len_query x d_head\n",
    "        proj_key = self._prepare_proj(proj_key)  # batch_size*h x len_key x d_head\n",
    "        proj_value = self._prepare_proj(proj_value)  # batch_size*h x len_key x d_head\n",
    "\n",
    "        # get dotproduct softmax attns for each head\n",
    "        attns = torch.bmm(proj_query, proj_key.transpose(1, 2))  # batch_size*h x len_query x len_key\n",
    "        attns = attns / math.sqrt(self.d_head)\n",
    "        attns = attns.view(b, self.h, len_query, len_key)\n",
    "#         attns = attns.masked_fill_(mask.unsqueeze(1), -float('inf'))\n",
    "        attns = self.sm(attns.view(-1, len_key))\n",
    "    \n",
    "        # return mean attention from all heads as coverage \n",
    "        coverage = torch.mean(attns.view(b, self.h, len_query, len_key), dim=1)\n",
    "        attns = self.attn_dropout(attns)\n",
    "        attns = attns.view(b * self.h, len_query, len_key)\n",
    "\n",
    "        # apply attns on value\n",
    "        out = torch.bmm(attns, proj_value)  # batch_size*h x len_query x d_head\n",
    "        out = out.view(b, self.h, len_query, self.d_head).transpose(1, 2).contiguous()\n",
    "        out = self.fc_concat(out.view(b, len_query, self.h * self.d_head))\n",
    "        out = self.layernorm(query + self.dropout(out))\n",
    "        return out, coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab, max_seq_length, embedding_size=256, hidden_size=256, num_layers=1, embedding_dropout=0.5, \n",
    "                 rnn_dropout=0.5, teacher_forcing_ratio=0.5,\n",
    "                 initialize=None):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.vocab = vocab\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding_dropout = embedding_dropout\n",
    "        self.rnn_dropout = rnn_dropout if num_layers > 1 else 0.0\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "        self.initialize = initialize\n",
    "\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Embedding(self.vocab_size, self.embedding_size, padding_idx=IDX_PAD),\n",
    "            nn.Dropout(self.embedding_dropout)\n",
    "        )\n",
    "\n",
    "        self.attn = MultiHeadAttention(32, self.hidden_size, 0.2)\n",
    "        \n",
    "        self.rnn = nn.GRU(self.embedding_size, self.hidden_size, self.num_layers, batch_first=True, bias=True,\n",
    "                          dropout=self.rnn_dropout)\n",
    "\n",
    "        self.fc = nn.Linear(self.hidden_size, self.vocab_size)\n",
    "\n",
    "        if self.initialize is not None:\n",
    "            self.initialize(self)\n",
    "\n",
    "\n",
    "    def forward(self, enc_inputs, enc_input_sizes, hidden, labels=None, label_sizes=None):\n",
    "\n",
    "        if self.training:\n",
    "            assert labels is not None and label_sizes is not None, \"Need labels in trainings mode.\"\n",
    "\n",
    "        use_cuda = next(self.parameters()).is_cuda\n",
    "\n",
    "        batch_size = enc_inputs.size(0)\n",
    "        inputs = torch.LongTensor([self.vocab(\"<sos>\")] * batch_size).view(batch_size, 1)\n",
    "        inputs = inputs.cuda() if use_cuda else inputs\n",
    "\n",
    "        max_length = labels.size(1) if labels is not None else self.max_seq_length + 1\n",
    "\n",
    "#         mask = self.get_mask(enc_input_sizes).unsqueeze(1)\n",
    "#         mask = mask.cuda() if use_cuda else mask\n",
    "        mask = None\n",
    "\n",
    "        dec_output_sizes = torch.LongTensor(batch_size).fill_(max_length)\n",
    "        dec_output_sizes = dec_output_sizes.cuda() if use_cuda else dec_output_sizes\n",
    "\n",
    "        dec_outputs = []\n",
    "        for t in range(max_length):\n",
    "\n",
    "            outputs, hidden = self.step(inputs, hidden, enc_inputs, mask)\n",
    "            dec_outputs.append(outputs)\n",
    "\n",
    "            inputs = outputs.topk(1)[1].view(batch_size, 1)\n",
    "\n",
    "            dec_output_sizes[inputs.squeeze(1).eq(self.vocab('<eos>')) * dec_output_sizes.gt(t)] = t\n",
    "            if labels is None and dec_output_sizes.le(t + 1).all():\n",
    "                break\n",
    "\n",
    "            if self.training and random.random() < self.teacher_forcing_ratio:\n",
    "                inputs = labels[:, t].view(batch_size, 1)\n",
    "\n",
    "        dec_outputs = torch.cat(dec_outputs, dim=1)\n",
    "\n",
    "        return dec_outputs, dec_output_sizes\n",
    "\n",
    "    def step(self, inputs, hidden, enc_inputs, mask):\n",
    "        batch_size, output_size = inputs.size(0), inputs.size(1)\n",
    "\n",
    "        embeddings = self.embedding(inputs)\n",
    "\n",
    "        outputs, hidden = self.rnn(embeddings, hidden)\n",
    "\n",
    "        outputs, _ = self.attn(outputs, enc_inputs, enc_inputs, mask)\n",
    "\n",
    "        outputs = self.fc(outputs.contiguous().squeeze(1))\n",
    "\n",
    "        outputs = torch.log_softmax(outputs, dim=1).view(batch_size, output_size, -1)\n",
    "\n",
    "        return outputs, hidden\n",
    "\n",
    "    @staticmethod\n",
    "    def get_mask(lengths):\n",
    "        batch_size = lengths.numel()\n",
    "        mask = (torch.arange(0, lengths.max()).type_as(lengths).repeat(batch_size, 1).gt(lengths.unsqueeze(1)))\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for model: Decoder\n",
      "________________________________________________________________________________\n",
      "Layer (type)                        Shape                           Param #     \n",
      "================================================================================\n",
      "embedding.0 (Embedding)             ((15657, 512),)                 8016384     \n",
      "________________________________________________________________________________\n",
      "embedding.1 (Dropout)               ()                              0           \n",
      "________________________________________________________________________________\n",
      "attn.fc_query (Linear)              ((512, 512),)                   262144      \n",
      "________________________________________________________________________________\n",
      "attn.fc_key (Linear)                ((512, 512),)                   262144      \n",
      "________________________________________________________________________________\n",
      "attn.fc_value (Linear)              ((512, 512),)                   262144      \n",
      "________________________________________________________________________________\n",
      "attn.fc_concat (Linear)             ((512, 512),)                   262144      \n",
      "________________________________________________________________________________\n",
      "attn.sm (Softmax)                   ()                              0           \n",
      "________________________________________________________________________________\n",
      "attn.dropout (Dropout)              ()                              0           \n",
      "________________________________________________________________________________\n",
      "attn.attn_dropout (Dropout)         ()                              0           \n",
      "________________________________________________________________________________\n",
      "attn.layernorm (LayerNorm)          ((512,), (512,))                1024        \n",
      "________________________________________________________________________________\n",
      "rnn (GRU)                           ((1536, 512), (1536, 512), (153 3151872     \n",
      "________________________________________________________________________________\n",
      "fc (Linear)                         ((15657, 512), (15657,))        8032041     \n",
      "================================================================================\n",
      "Total params:         20,249,897\n",
      "Trainable params:     20,249,897\n",
      "________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([7]), 2, torch.Size([128, 13, 15657]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_cpu = Decoder(output_vocab, H.SEQ_MAX_LEN, H.RNN_HIDDEN_SIZE*2, H.RNN_HIDDEN_SIZE*2,\n",
    "                         num_layers=H.RNN_NUM_LAYERS, rnn_dropout=H.RNN_DROPOUT, \n",
    "                         embedding_dropout=H.EMBEDDING_DROPOUT, teacher_forcing_ratio=H.TEACHER_FORCING_RATIO)\n",
    "\n",
    "decoder_cpu.train()\n",
    "decoder_output_cpu = decoder_cpu(enc_outputs_cpu, enc_output_sizes_cpu, enc_hidden_cpu, labels_cpu, label_sizes_cpu)\n",
    "\n",
    "print(model_summary(decoder_cpu))\n",
    "\n",
    "inputs_cpu[0].shape, len(decoder_output_cpu), decoder_output_cpu[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralMachineTranslator(nn.Module):\n",
    "    def __init__(self, src_vocab, tgt_vocab, max_seq_length, embedding_size=256, rnn_hidden_size=256, \n",
    "                 rnn_num_layers=1, rnn_dropout=0.5, embedding_dropout=0.5, teacher_forcing_ratio=0.5, \n",
    "                 initialize=None):\n",
    "        super(NeuralMachineTranslator, self).__init__()\n",
    "        self.src_vocab = src_vocab\n",
    "        self.tgt_vocab = tgt_vocab\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.embedding_size = embedding_size\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.rnn_num_layers = rnn_num_layers\n",
    "        self.embedding_dropout = embedding_dropout\n",
    "        self.rnn_dropout = rnn_dropout\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "        self.initialize = initialize\n",
    "\n",
    "        self.enc = Encoder(len(src_vocab), embedding_size=self.embedding_size, \n",
    "                           hidden_size=self.rnn_hidden_size, num_layers=self.rnn_num_layers, \n",
    "                           embedding_dropout=self.embedding_dropout, rnn_dropout=self.rnn_dropout, \n",
    "                           bidirectional=True, initialize=self.initialize)\n",
    "\n",
    "        self.dec = Decoder(tgt_vocab, max_seq_length=self.max_seq_length, embedding_size=self.rnn_hidden_size *2,\n",
    "                           hidden_size=self.rnn_hidden_size * 2, num_layers=self.rnn_num_layers, \n",
    "                           embedding_dropout=self.embedding_dropout, rnn_dropout=self.rnn_dropout, \n",
    "                           teacher_forcing_ratio=self.teacher_forcing_ratio, initialize=self.initialize)\n",
    "\n",
    "    def forward(self, inputs, input_sizes, labels=None, label_sizes=None):\n",
    "        outputs, output_sizes, hidden = self.enc(inputs, input_sizes)\n",
    "\n",
    "        outputs, output_sizes = self.dec(outputs, output_sizes, hidden, labels, label_sizes)\n",
    "\n",
    "        return outputs, output_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, model, loader, optimizer, scheduler, criterion, decoder, scorer, max_grade_norm=None):\n",
    "        self.model = model\n",
    "        self.loader = loader\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.criterion = criterion\n",
    "        self.decoder = decoder\n",
    "        self.scorer = scorer\n",
    "        self.max_grade_norm = max_grade_norm\n",
    "        self.use_cuda = next(self.model.parameters()).is_cuda\n",
    "\n",
    "    def __call__(self, epoch):\n",
    "        self.model.train(True)\n",
    "\n",
    "        self.scheduler.step(epoch)\n",
    "\n",
    "        train_lr = [float(param_group['lr']) for param_group in self.optimizer.param_groups][0]\n",
    "\n",
    "        total_size, total_loss, total_score = 0, 0.0, 0.0\n",
    "        for idx_batch, batch in enumerate(self.loader):\n",
    "            inputs, input_sizes = getattr(batch, SRC_FIELD_NAME)\n",
    "            labels, label_sizes = getattr(batch, TGT_FIELD_NAME)\n",
    "            if next(self.model.parameters()).is_cuda:\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "            outputs, output_sizes = self.model(inputs, input_sizes, labels, label_sizes)\n",
    "\n",
    "            loss = self.criterion(outputs, output_sizes, labels, label_sizes)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "#             preds_seq, label_seq = self.decoder(outputs, output_sizes, labels, label_sizes)\n",
    "#             total_score += self.scorer(preds_seq, label_seq)\n",
    "            total_score += 1\n",
    "    \n",
    "            total_size += inputs.size(0)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            if self.max_grade_norm is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grade_norm)\n",
    "            self.optimizer.step()\n",
    "\n",
    "            del outputs\n",
    "            del loss\n",
    "\n",
    "        return total_loss / total_size, 1.0 - min(1.0, total_score / total_size), train_lr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator(object):\n",
    "    def __init__(self, model, loader, criterion, decoder, scorer):\n",
    "        self.model = model\n",
    "        self.loader = loader\n",
    "        self.criterion = criterion\n",
    "        self.decoder = decoder\n",
    "        self.scorer = scorer\n",
    "        self.use_cuda = next(self.model.parameters()).is_cuda\n",
    "\n",
    "    def __call__(self):\n",
    "        self.model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            total_size, total_loss, total_score = 0, 0.0, 0.0\n",
    "            for idx_batch, batch in enumerate(self.loader):\n",
    "                inputs, input_sizes = getattr(batch, SRC_FIELD_NAME)\n",
    "                labels, label_sizes = getattr(batch, TGT_FIELD_NAME)\n",
    "                if next(self.model.parameters()).is_cuda:\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "                outputs, output_sizes = self.model(inputs, input_sizes, labels, label_sizes)\n",
    "\n",
    "#                 loss = self.criterion(outputs, output_sizes, labels, label_sizes)\n",
    "#                 total_loss += loss.item()\n",
    "                total_loss += 1\n",
    "\n",
    "                preds_seq, label_seq = self.decoder(outputs, output_sizes, labels, label_sizes)\n",
    "                total_score += self.scorer(preds_seq, label_seq)\n",
    "\n",
    "                total_size += inputs.size(0)\n",
    "\n",
    "                del outputs\n",
    "#                 del loss\n",
    "\n",
    "            return total_loss / total_size, 1.0 - min(1.0, total_score / total_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, padding_idx, label_smoothing=0.0):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(reduction='sum')\n",
    "        self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0 - label_smoothing\n",
    "        self.smoothing = label_smoothing\n",
    "\n",
    "    def __call__(self, inputs, input_sizes, labels, label_sizes):\n",
    "        return self.forward(inputs, input_sizes, labels, label_sizes)\n",
    "\n",
    "    def forward(self, inputs, input_sizes, labels, label_sizes):\n",
    "        b, t, c = inputs.size()\n",
    "        inputs = inputs.view(b * t, c)\n",
    "\n",
    "        b, t = labels.size()\n",
    "        labels = labels.view(b * t)\n",
    "\n",
    "        true_dist = inputs.data.clone()\n",
    "        true_dist.fill_(self.smoothing / (inputs.size(1) - 2))\n",
    "        true_dist.scatter_(1, labels.data.unsqueeze(1), self.confidence)\n",
    "        true_dist[:, self.padding_idx] = 0\n",
    "\n",
    "        mask = torch.nonzero(labels.data == self.padding_idx)\n",
    "        if mask.dim() > 0:\n",
    "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "\n",
    "        return self.criterion(inputs, true_dist.detach())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STSDecoder(object):\n",
    "    def __init__(self, vocab):\n",
    "        self.vocab = vocab\n",
    "\n",
    "    @staticmethod\n",
    "    def decode_labels(labels, label_sizes, vocab):\n",
    "        idx_sos, idx_eos, idx_pad = vocab('<sos>'), vocab('<eos>'), vocab('<pad>')\n",
    "\n",
    "        lseq = []\n",
    "        for seq, size in zip(labels, label_sizes):\n",
    "            lseq.append(' '.join([vocab(c.item()) for c in seq[0:size - 1] if c not in [idx_sos, idx_eos, idx_pad]]))\n",
    "\n",
    "        return lseq\n",
    "\n",
    "    @staticmethod\n",
    "    def decode_probas(probas, probas_sizes, vocab, probabilities=False):\n",
    "        max_vals, max_indices = torch.max(probas, 2)\n",
    "        idx_sos, idx_eos, idx_pad = vocab('<sos>'), vocab('<eos>'), vocab('<pad>')\n",
    "\n",
    "        decoded_seq = []\n",
    "        for seq_idx, seq_len, seq_proba in zip(max_indices.cpu(), probas_sizes, max_vals):\n",
    "            txt, probas = '', []\n",
    "\n",
    "            for i in range(min(seq_len, len(seq_idx))):\n",
    "                c = seq_idx[i].item()\n",
    "                if c in [idx_sos, idx_eos, idx_pad]:\n",
    "                    continue\n",
    "                txt += vocab(c) + ' '\n",
    "                probas.append(math.exp(seq_proba[i].item()))\n",
    "\n",
    "            if probabilities:\n",
    "                decoded_seq.append((txt.strip(), stats.mean(probas) if len(probas) > 0 else 0))\n",
    "            else:\n",
    "                decoded_seq.append(txt.strip())\n",
    "        return decoded_seq\n",
    "\n",
    "    def __call__(self, inputs, inputs_sizes, labels=None, label_sizes=None, probabilities=False):\n",
    "\n",
    "        decoder_seq = self.decode_probas(inputs, inputs_sizes, self.vocab, probabilities=probabilities)\n",
    "\n",
    "        label_seq = None\n",
    "        if labels is not None and label_sizes is not None:\n",
    "            label_seq = self.decode_labels(labels, label_sizes, self.vocab)\n",
    "\n",
    "        return decoder_seq, label_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.scorer import Scorer\n",
    "from lib.stopping import Stopping\n",
    "\n",
    "m = Metric([('train_loss', np.inf), ('train_score', np.inf), ('valid_loss', np.inf), ('valid_score', 0),\n",
    "            ('train_lr', 0), ('valid_cer', np.inf)])\n",
    "\n",
    "model = NeuralMachineTranslator(input_vocab, output_vocab, H.SEQ_MAX_LEN, \n",
    "                                embedding_size=H.EMBEDDING_SIZE, rnn_hidden_size=H.RNN_HIDDEN_SIZE,\n",
    "                                rnn_num_layers=H.RNN_NUM_LAYERS, rnn_dropout=H.RNN_DROPOUT, \n",
    "                                embedding_dropout=H.EMBEDDING_DROPOUT, \n",
    "                                teacher_forcing_ratio=H.TEACHER_FORCING_RATIO,\n",
    "                                initialize=torch_weight_init)\n",
    "if H.USE_CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "logging.info(model_summary(model, line_length=100))\n",
    "\n",
    "if H.PRELOAD_MODEL_PATH:\n",
    "    path = os.path.join(H.EXPERIMENT, H.PRELOAD_MODEL_PATH)\n",
    "    state = torch.load(path)\n",
    "    model.load_state_dict(state)\n",
    "    logging.info(\"Preloaded model: {}\".format(path))\n",
    "\n",
    "criterion = LabelSmoothingLoss(padding_idx=IDX_PAD, label_smoothing=H.LABEL_SMOOTHING)\n",
    "\n",
    "sts_decoder = STSDecoder(output_vocab)\n",
    "\n",
    "scorer = Scorer()\n",
    "\n",
    "optimizer = optim.Adam(list(filter(lambda p: p.requires_grad, model.parameters())),\n",
    "                       amsgrad=False,\n",
    "                       betas=(0.9, 0.999),\n",
    "                       eps=1e-08,\n",
    "                       lr=H.LR,\n",
    "                       weight_decay=H.WEIGHT_DECAY)\n",
    "\n",
    "stopping = Stopping(model, patience=H.STOPPING_PATIENCE)\n",
    "\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=[H.LR_LAMBDA])\n",
    "\n",
    "tlogger = TensorboardLogger(root_dir=H.EXPERIMENT, experiment_dir=H.TIMESTAMP)  # PytorchLogger()\n",
    "\n",
    "checkpoint = Checkpoint(model, optimizer, stopping, m,\n",
    "                        root_dir=H.EXPERIMENT, experiment_dir=H.TIMESTAMP, restore_from=-1,\n",
    "                        interval=H.CHECKPOINT_INTERVAL, verbose=0)\n",
    "\n",
    "trainer = Trainer(model, train_iter, optimizer, scheduler, criterion, sts_decoder, scorer, H.MAX_GRAD_NORM)\n",
    "\n",
    "evaluator = Evaluator(model, valid_iter, criterion, sts_decoder, scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_start = 1\n",
    "if H.CHECKPOINT_RESTORE:\n",
    "    epoch_start = checkpoint.restore() + 1\n",
    "    train_loader.batch_sampler.shuffle(epoch_start)\n",
    "\n",
    "epoch = epoch_start\n",
    "try:\n",
    "    epoch_itr = tlogger.set_itr(range(epoch_start, H.MAX_EPOCHS + 1))\n",
    "\n",
    "    for epoch in epoch_itr:\n",
    "\n",
    "        with DelayedKeyboardInterrupt():\n",
    "\n",
    "            m.train_loss, m.train_score, m.train_lr = trainer(epoch)\n",
    "\n",
    "            m.valid_loss, m.valid_score = evaluator()\n",
    "\n",
    "            if checkpoint:\n",
    "                checkpoint.step(epoch)\n",
    "\n",
    "            stopping_flag = stopping.step(epoch, m.valid_loss, m.valid_score)\n",
    "\n",
    "            epoch_itr.log_values(m.train_loss, m.train_score, m.train_lr, m.valid_loss, m.valid_score,\n",
    "                                 stopping.best_score_epoch, stopping.best_score)\n",
    "\n",
    "            if stopping_flag:\n",
    "                logger.info(\n",
    "                    \"Early stopping at epoch: %d, score %f\" % (stopping.best_score_epoch, stopping.best_score))\n",
    "                break\n",
    "\n",
    "#             train_loader.batch_sampler.shuffle(epoch)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    logger.info(\"Training interrupted at: {}\".format(epoch))\n",
    "    pass\n",
    "\n",
    "checkpoint.create(epoch)\n",
    "\n",
    "model.load_state_dict(stopping.best_score_state)\n",
    "torch.save(model.state_dict(), os.path.join(H.EXPERIMENT, H.MODEL_NAME + '.tar'))\n",
    "\n",
    "logger.info(repr(tlogger))\n",
    "logger.info(repr(stopping))\n",
    "logger.info(repr(checkpoint))\n",
    "\n",
    "logger.info(\"Training end.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pre = NeuralMachineTranslator(input_vocab, output_vocab, H.SEQ_MAX_LEN, \n",
    "                                    embedding_size=H.EMBEDDING_SIZE, rnn_hidden_size=H.RNN_HIDDEN_SIZE,\n",
    "                                    rnn_num_layers=H.RNN_NUM_LAYERS, rnn_dropout=H.RNN_DROPOUT, \n",
    "                                    embedding_dropout=H.EMBEDDING_DROPOUT, \n",
    "                                    teacher_forcing_ratio=H.TEACHER_FORCING_RATIO,\n",
    "                                    initialize=torch_weight_init)\n",
    "if H.USE_CUDA:\n",
    "    model_pre.cuda()\n",
    "\n",
    "path = os.path.join(H.EXPERIMENT, H.MODEL_NAME + '.tar')\n",
    "state = torch.load(path)\n",
    "model_pre.load_state_dict(state)\n",
    "\n",
    "sts_decoder = STSDecoder(output_vocab)\n",
    "scorer = Scorer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recognizer(object):\n",
    "    def __init__(self, model, decoder, loader, probabilities=False):\n",
    "        self.model = model\n",
    "        self.decoder = decoder\n",
    "        self.loader = loader\n",
    "        self.probabilities = probabilities\n",
    "\n",
    "        self.use_cuda = next(self.model.parameters()).is_cuda\n",
    "\n",
    "    def __call__(self):\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "\n",
    "            decoder_seq = []\n",
    "            for idx_batch, batch in enumerate(self.loader):\n",
    "                inputs, input_sizes = getattr(batch, SRC_FIELD_NAME)\n",
    "\n",
    "                if next(self.model.parameters()).is_cuda:\n",
    "                    inputs = inputs.cuda()\n",
    "\n",
    "                logits, logit_sizes = self.model(inputs, input_sizes)\n",
    "\n",
    "                seq, _ = self.decoder(logits, logit_sizes, None, None, probabilities=self.probabilities)\n",
    "\n",
    "                decoder_seq.extend(seq)\n",
    "\n",
    "                del logits\n",
    "\n",
    "        return decoder_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer = Recognizer(model_pre, sts_decoder, test_iter)\n",
    "\n",
    "hypotheses = recognizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts = []\n",
    "for idx_batch, batch in enumerate(test_iter):\n",
    "    labels, label_sizes = getattr(batch, TGT_FIELD_NAME)\n",
    "\n",
    "    label_seq = STSDecoder.decode_labels(labels, label_sizes, output_vocab)\n",
    "    transcripts.extend(label_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ich mag hunde .',\n",
       " 'hört bitte damit auf .',\n",
       " \"kontrollieren sie 's einfach .\",\n",
       " 'tom war angewidert .',\n",
       " 'hallo , alle miteinander !']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcripts[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ich mag hunde .',\n",
       " 'unterlassen sie es bitte !',\n",
       " 'kontrollier sie einfach .',\n",
       " 'tom war angewidert .',\n",
       " 'hallo zusammen !']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypotheses[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Summary \n",
      "Bleu: 41.110\n",
      "WER:  35.228\n",
      "CER:  33.395\n",
      "ACC:  17.702\n"
     ]
    }
   ],
   "source": [
    "from lib.scorer import Scorer\n",
    "\n",
    "recognizer = Recognizer(model_pre, sts_decoder, test_iter)\n",
    "\n",
    "hypotheses = recognizer()\n",
    "\n",
    "transcripts = []\n",
    "for idx_batch, batch in enumerate(test_iter):\n",
    "    target_variables, target_lengths = getattr(batch, TGT_FIELD_NAME)    \n",
    "    label_seq = STSDecoder.decode_labels(target_variables, target_lengths, output_vocab)\n",
    "    transcripts.extend(label_seq)\n",
    "\n",
    "bleu = Scorer.get_moses_multi_bleu(hypotheses, transcripts, lowercase=False)\n",
    "wer, cer = Scorer.get_wer_cer(hypotheses, transcripts)\n",
    "acc = Scorer.get_acc(hypotheses, transcripts)\n",
    "\n",
    "print('Test Summary \\n'\n",
    "        'Bleu: {bleu:.3f}\\n'\n",
    "        'WER:  {wer:.3f}\\n'\n",
    "        'CER:  {cer:.3f}\\n'\n",
    "        'ACC:  {acc:.3f}'.format(bleu=bleu, wer=wer * 100, cer=cer * 100, acc=acc * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(model, vocab, encoder_outputs, encoder_output_sizes, encoder_hidden,\n",
    "                beam_size=3, alpha=0.1, beta=0.3, max_seq_len=64):\n",
    "    vocab_size = len(vocab)\n",
    "    idx_sos, idx_eos, idx_pad = vocab('<sos>'), vocab('<eos>'), vocab('<pad>')\n",
    "    use_cuda = next(model.parameters()).is_cuda\n",
    "\n",
    "    batch_size = encoder_outputs.size(0)\n",
    "    inputs = torch.LongTensor([vocab(\"<sos>\")] * batch_size).view(batch_size, 1)\n",
    "    inputs = inputs.cuda() if use_cuda else inputs\n",
    "\n",
    "    #         mask = self.get_mask(enc_input_sizes).unsqueeze(1)\n",
    "    #         mask = mask.cuda() if use_cuda else mask\n",
    "    mask = None\n",
    "\n",
    "    decode_outputs, decode_hidden = model.dec.step(inputs, encoder_hidden, encoder_outputs, mask)\n",
    "\n",
    "    search_outputs = []\n",
    "\n",
    "    for batch_idx in range(decode_outputs.size(0)):\n",
    "        probas = []\n",
    "        preds = []\n",
    "\n",
    "        dec_outputs = decode_outputs[batch_idx].unsqueeze(0).contiguous()\n",
    "        dec_hidden = decode_hidden[:, batch_idx, :].unsqueeze(1).contiguous()\n",
    "        enc_outputs = encoder_outputs[batch_idx, :, :].unsqueeze(0).contiguous()\n",
    "\n",
    "        scores, scores_idx = dec_outputs.view(-1).topk(beam_size)\n",
    "        scores_idx = scores_idx.fmod(vocab_size).view(beam_size, 1)\n",
    "\n",
    "        dec_inputs = scores_idx.view(1, beam_size, 1)\n",
    "        scores = scores.view(beam_size)\n",
    "        dec_hidden = dec_hidden.repeat(1, beam_size, 1)\n",
    "        enc_outputs = enc_outputs.repeat(beam_size, 1, 1)\n",
    "\n",
    "        remaining_beams = beam_size\n",
    "        for step in range(max_seq_len):\n",
    "            dec_outputs, dec_hidden = model.dec.step(dec_inputs[-1], dec_hidden, enc_outputs, mask)\n",
    "\n",
    "            dec_outputs = scores.unsqueeze(1) + dec_outputs[:, -1, :]\n",
    "            scores, scores_idx = dec_outputs.view(-1).topk(remaining_beams)\n",
    "\n",
    "            scores_idx = scores_idx.fmod(vocab_size).view(remaining_beams, 1)\n",
    "\n",
    "            dec_inputs = torch.cat((dec_inputs, scores_idx.unsqueeze(0)), 0)\n",
    "\n",
    "            index = (scores_idx[:, -1].eq(idx_eos) + scores_idx[:, -1].eq(idx_pad)).flatten()\n",
    "\n",
    "            finished, continue_idx = index.nonzero().flatten(), (index ^ 1).nonzero().flatten()\n",
    "\n",
    "            if preds == [] and (step + 1) == max_seq_len:\n",
    "                finished = continue_idx\n",
    "                remaining_beams = 0\n",
    "                \n",
    "            for idx in finished:\n",
    "                probas.append(scores[idx].item())\n",
    "                preds.append(dec_inputs[:, idx].flatten().tolist())\n",
    "                remaining_beams -= 1\n",
    "\n",
    "            if remaining_beams <= 0:\n",
    "                break\n",
    "\n",
    "            if len(continue_idx) > 0:\n",
    "                dec_inputs = dec_inputs.index_select(1, continue_idx)\n",
    "                dec_hidden = dec_hidden.index_select(1, continue_idx)\n",
    "                enc_outputs = enc_outputs.index_select(0, continue_idx)\n",
    "                scores = scores.index_select(0, continue_idx)\n",
    "\n",
    "        len_penalties = [math.pow(len(pred), alpha) for pred in preds]\n",
    "        final_scores = [probas[i] / len_penalties[i] for i in range(len(preds))]\n",
    "        sorted_scores_arg = sorted(range(len(preds)), key=lambda i: -final_scores[i])\n",
    "        best_beam = sorted_scores_arg[0]\n",
    "\n",
    "        search_outputs.append(preds[best_beam])\n",
    "\n",
    "    return search_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 48s, sys: 619 ms, total: 7min 49s\n",
      "Wall time: 7min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_pre.eval()\n",
    "with torch.no_grad():\n",
    "\n",
    "    hypotheses = []\n",
    "    references = []\n",
    "    for idx_batch, batch in enumerate(test_iter):\n",
    "        inputs, input_sizes = getattr(batch, SRC_FIELD_NAME)\n",
    "        labels, label_sizes = getattr(batch, TGT_FIELD_NAME)\n",
    "        if next(model_pre.parameters()).is_cuda:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        enc_outputs, enc_output_sizes, enc_hidden = model_pre.enc(inputs, input_sizes)\n",
    "        max_seq_len = labels.size(1) if labels is not None else H.MAX_SEQ_LENGTH\n",
    "         \n",
    "        results = beam_search(model_pre, output_vocab, \n",
    "                              enc_outputs, enc_output_sizes, enc_hidden, \n",
    "                              beam_size=20, alpha=0.1, beta=0.3, max_seq_len=64)\n",
    "\n",
    "        for row in results:\n",
    "            hypotheses.append(' '.join([output_vocab(t) for t in row if t not in [IDX_PAD, IDX_SOS, IDX_EOS]]))\n",
    "\n",
    "        references.extend(STSDecoder.decode_labels(labels[:,1:], label_sizes-1, output_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ich mag hunde .',\n",
       " 'unterlassen sie es bitte',\n",
       " 'kontrollier sie einfach .',\n",
       " 'tom war angewidert .',\n",
       " 'hallo zusammen !']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypotheses[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ich mag hunde .',\n",
       " 'hört bitte damit auf .',\n",
       " \"kontrollieren sie 's einfach .\",\n",
       " 'tom war angewidert .',\n",
       " 'hallo , alle miteinander !']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Summary \n",
      "Bleu: 38.210\n",
      "WER:  37.487\n",
      "CER:  35.314\n",
      "ACC:  17.135\n"
     ]
    }
   ],
   "source": [
    "from lib.scorer import Scorer\n",
    "\n",
    "bleu = Scorer.get_moses_multi_bleu(hypotheses, references, lowercase=False)\n",
    "wer, cer = Scorer.get_wer_cer(hypotheses, references)\n",
    "acc = Scorer.get_acc(hypotheses, references)\n",
    "\n",
    "print('Test Summary \\n'\n",
    "        'Bleu: {bleu:.3f}\\n'\n",
    "        'WER:  {wer:.3f}\\n'\n",
    "        'CER:  {cer:.3f}\\n'\n",
    "        'ACC:  {acc:.3f}'.format(bleu=bleu, wer=wer * 100, cer=cer * 100, acc=acc * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type in a source sequence:I am at home.\n",
      ">>  I am at home.\n",
      "['i', 'am', 'at', 'home', '.']\n",
      "<<  ich bin zu hause .\n",
      "Type in a source sequence:\n",
      ">>  \n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    seq_str = input(\"Type in a source sequence:\")\n",
    "    print(\">> \", seq_str)\n",
    "    if not len(seq_str):\n",
    "        break\n",
    "    #seq = seq_str.strip().lower().split()\n",
    "    seq = tokenize_en(seq_str.strip().lower())\n",
    "    print(seq)\n",
    "\n",
    "    seq_id = [input_vocab(tok) for tok in seq]\n",
    "\n",
    "    model_pre.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        src_id_seq = torch.LongTensor(seq_id).view(1, -1)\n",
    "        src_id_seq = src_id_seq.cuda() if torch.cuda.is_available() else src_id_seq\n",
    "        \n",
    "        src_id_length = torch.LongTensor([len(seq_id)])\n",
    "\n",
    "        outputs, outputs_sizes = model_pre(src_id_seq, src_id_length)\n",
    "        tgt_seq = STSDecoder.decode_probas(outputs, outputs_sizes, output_vocab)\n",
    "        print(\"<< \", ' '.join(tgt_seq))\n",
    "\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
